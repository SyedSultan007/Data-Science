{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "448CDAPjqfQr",
        "y-Ehk30pYrdP",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyedSultan007/Data-Science/blob/main/Syed_Sultan_ML_Classification_Mobile_Price_Range_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - ML Classification_Mobile Price Range Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1** - Syed Sultan\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Summary**\n",
        "\n",
        "Project for Predicting Price Range of Mobiles\n",
        "\n",
        "Introduction\n",
        "This project intends to predict the price range of mobiles based on the classification model. The data set contains 2000 mobile records with 21 attributes like battery power, RAM, screen dimension, and the mobile supports features or not like 3G, 4G, or dual SIM. The `price_range` target variable is split into four categories: 0 (low), 1 (medium), 2 (high), and 3 (very high). Three machine learning algorithms, Logistic Regression, Decision Tree, and Random Forest, are applied to train and test the classification model.\n",
        "    \n",
        "#### Dataset Description\n",
        "The dataset encompasses many of the factors that define mobile prices, for example:\n",
        "- **Battery Power**: The amount of power in the battery in mAh.\n",
        "- **RAM**: Amount of Random Access Memory.\n",
        "- **Pixel Height and Width**: Resolution parameters.\n",
        "- **Clock Speed**: CPU in GHz.\n",
        "- **Mobile Weight**: Physical weight of the mobile.\n",
        "- **Cores**: CPU cores.\n",
        "\n",
        "All of these features, except `price_range`, are either numeric or binary (whether a feature is available).There's no missing data, which helps simplify preprocessing.\n",
        "\n",
        "#### Method\n",
        "\n",
        "\n",
        "1. **Pre-processing**\n",
        "   Since the data is all numeric, there is no encoding to be made.\n",
        "- The dataset is divided into training and test sets (80% training, 20% testing) to be used in the evaluation of the model.\n",
        "-Features will be standardized where appropriate-for instance, `battery_power` and `ram-to improve performance, especially for models such as Logistic Regression.\n",
        "\n",
        "2. **Model Implementation:**\n",
        "Logistic Regression: This linear model assumes a linear relationship between the features and the log-odds of the class. It is quite easy to interpret and works pretty well for classification tasks\n",
        "Decision Tree: A non-linear, tree-based model that splits the data based on feature values. Since it is completely based on the features of the data, it is easily interpretable and can also represent interactions between features.\n",
        "- **Random Forest**: It is an ensemble approach that combines many Decision Trees and primarily focuses on increasing accuracy while reducing overfitting. This approach is applicable to big datasets with very strong correlated features.\n",
        "3. **Evaluation Metrics**:\n",
        "- **Accuracy**: Percentage of instances correctly classified.\n",
        "- **Precision, Recall, and F1-Score**: Used to measure the trade-off between precision and recall for each of the two models.\n",
        "- **Confusion Matrix**: Helps understand what the model thinks for each class.\n",
        "\n",
        "#### Results and Discussion\n",
        "\n",
        "- **Logistic Regression**: Simple, yet gave fairly decent accuracy on this data set. Is certainly limited on non-linear relationships between features.\n",
        "Decision Tree: Does quite well, and provides good insights into which features it chooses as important for predicting a price range, for example RAM, battery power, but it can clearly cause overfitting on the training data.\n",
        "- **Random Forest**: Chanced to be performing better than both Logistic Regression and Decision Tree models. But it had produced an efficient reduction of overfitting through the use of an average for multiple trees, thus providing a good accuracy rate on unseen data.\n",
        "\n",
        " There was a comparison between these models based on their precision plus other evaluation criteria. Although Random Forest tends to perform better in terms of accuracy and robustness, Logistic Regression had provided a simpler solution with moderate performance in fewer steps in time.\n",
        "\n",
        " #### Conclusion\n",
        "\n",
        "It will thus be demonstrated to implement various classification models in predicting the mobile price range using a relevant set of features. Of all the models, Random Forest was the one that best covered the characteristics because it addresses complex nonlinear relationships and is immune to overfitting. Although less accurate, Logistic Regression provided an easier alternative. Decision Trees are more interpretable in that they could explain why an attribute was ranked higher than another one but have a tendency to overfit unless pruned or controlled using hyperparameters.\n",
        "\n",
        "Even at that, future work may tune the hyperparameter to enhance this further through techniques like GridSearchCV. Feature engineering along the lines of combining or generating new features may unmask even stronger predictors of mobile price range."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Importing essential libraries for data analysis, visualization, and machine learning\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
        "import math\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import io\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import datetime\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Display libraries loaded successfully\n",
        "print(\"Libraries imported successfully.\")\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Data Science/Projects/ML Classification_Mobile Price Range Prediction/data_mobile_price_range.csv', encoding= 'unicode_escape')\n",
        "\n",
        "file_path = data\n",
        "Mobile_Price_Range= data\n",
        "df = data"
      ],
      "metadata": {
        "id": "LWam_bSGEpYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "Qjb2gajJEpOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Get basic information about the dataset\n",
        "print(\"\\nDataset Information:\")\n",
        "print(data.info())\n",
        "\n",
        "# Check for any missing values\n",
        "print(\"\\nMissing values in each column:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Get descriptive statistics (mean, std, min, max, etc.) for numerical columns\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(data.describe())"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "# Get the shape of the dataset\n",
        "rows, columns = data.shape\n",
        "\n",
        "# Print the number of rows and columns\n",
        "print(f\"Number of Rows: {rows}\")\n",
        "print(f\"Number of Columns: {columns}\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "print(\"Dataset Information:\")\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# Dataset Duplicate Value Count\n",
        "# Count the number of duplicate rows in the dataset\n",
        "duplicate_count = data.duplicated().sum()\n",
        "\n",
        "# Print the number of duplicate rows\n",
        "print(f\"Number of duplicate rows: {duplicate_count}\")"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Count the number of missing (null) values in each column\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "# Print the number of missing values for each column\n",
        "print(\"Missing values in each column:\")\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Simulating missing values for visualization purposes\n",
        "np.random.seed(0)  # For reproducibility\n",
        "data_missing = data.copy()\n",
        "missingness_ratio = 0.1  # 10% of values will be replaced with NaN\n",
        "for col in data_missing.columns:\n",
        "    data_missing.loc[data_missing.sample(frac=missingness_ratio).index, col] = np.nan\n",
        "\n",
        "# Plotting the heatmap of missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(data_missing.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the uploaded data set you, I observed the following information:\n",
        "\n",
        "1. **Rows and Columns**: 2000 rows and 21 columns in the data set\n",
        "2. **No missing values**: No column in the data set contains missing values; that is, every column contains 2000 non-null entries\n",
        "3. **Data types**:\n",
        "   - 19 columns of `int64`: They are binary variables and counts.\n",
        "   - 2 columns are of type `float64` (floating-point numbers), which are likely continuous variables.\n",
        "4. **Columns**:\n",
        "   The features of the dataset include `battery_power`, `blue` (Bluetooth), `clock_speed`, `dual_sim`, `fc` (front camera megapixels), `four_g` (4G capability), `int_memory` (internal memory), `m_dep` (mobile depth), `mobile_wt` (weight), and many others.\n",
        "It appears to be the column 'price_range' which is the target variable possibly of pricing category of mobile phones (low, medium, high, etc.)\n",
        "\n",
        "Missing data: There is no missing data at all but for visualization purpose, I can make for or other techniques to analyze this particular dataset. Would you like further exploration or insights?"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(\"Dataset Columns:\\n\")\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "print(\"\\nDataset Summary Statistics:\\n\")\n",
        "print(data.describe())"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a summary description of each variable in the data frame based on column names:\n",
        "\n",
        "1. **battery_power**: Total battery capacity for the mobile phone in mAh.\n",
        "2. **blue**: Binary of whether the mobile phone has Bluetooth or not. (`1` for Yes, `0` otherwise).\n",
        "3. **clock_speed**: The speed of processing the CPU of the mobile phone in GHz.\n",
        "4. **dual_sim**: It is a binary variable representing whether the mobile phone is dual SIM enabled or not (`1` if yes, `0` if no).\n",
        "5. **fc**: Concerned with the front camera resolution in megapixels.\n",
        "6. **four_g**: Another binary variable representing whether the mobile phone supports 4G or not (`1` if yes, `0` if no).\n",
        "7. **int_memory**: Internal memory of the mobile phone in GB.\n",
        "8. **m_dep**: Mobile depth in centimeter.\n",
        "9. **mobile_wt**: Weight of the mobile in grams.\n",
        "10. **n_cores**: Number of cores in the mobile processor.\n",
        "11. **pc**: Primary (rear) camera resolution. In megapixels.\n",
        "12. **px_height**: Pixel resolution height of mobile screen\n",
        "13. **px_width**:Pixel resolution width of mobile screen\n",
        "14. **ram**: Random Access Memory capacity. In MB\n",
        "15. **sc_h**: Screen height in centimeters.\n",
        "16. **sc_w**: Screen width in centimeters.\n",
        "17. **talk_time**: The maximum talk time battery life of the mobile phone (hours).\n",
        "18. **three_g**: Indicator variable whether the mobile phone supports 3G connectivity (`1` = Yes, `0` = No).\n",
        "19. **touch_screen**: Indicator variable whether the mobile phone has a touchscreen (`1` = Yes, `0` = No).\n",
        "20. **wifi**: Indicator variable if the mobile phone has support for wifi connectivity (`1` = Yes, `0` = No).\n",
        "**price_range**: Target variable that represents the range of prices for the cell phone offered (`0` = low cost, `1` = medium cost, `2` = high cost, `3` = very high cost).\n",
        "\n",
        "### Summary:\n",
        "- There are both categorical/binary and continuous variables that explain mobile phone specs.\n",
        "- The column **`price_range`** likely describes the target variable where the mobile phones are classified based on their ranges of price.\n",
        "\n",
        "Would you like some further analysis of any specific variables or insights?"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for column in data.columns:\n",
        "    unique_values = data[column].unique()\n",
        "    print(f\"Unique values in '{column}' ({len(unique_values)} unique values):\\n{unique_values}\\n\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "# 4. Feature scaling (normalizing or standardizing numerical columns)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# List of numeric columns to scale (excluding binary and target variables like 'price_range')\n",
        "numeric_cols = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep',\n",
        "                'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width',\n",
        "                'ram', 'sc_h', 'sc_w', 'talk_time']\n",
        "\n",
        "# Apply scaling to numerical columns\n",
        "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
        "\n",
        "# 5. Splitting the data into training and testing sets\n",
        "X = data.drop('price_range', axis=1)  # Features (all columns except target)\n",
        "y = data['price_range']               # Target (price range)\n",
        "\n",
        "# Perform an 80-20 train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print final transformed dataset details\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Steps:\n",
        "\n",
        "1. **Checked for Missing Values**:\n",
        "   - **No missing values** were found in the dataset, so no imputation or removal of rows/columns was necessary.\n",
        "\n",
        "2. **Dropped Unnecessary Columns**:\n",
        "   - While no specific columns were dropped in this case, I left the placeholder for dropping redundant columns based on domain knowledge, if needed.\n",
        "\n",
        "3. **Categorical Variable Handling**:\n",
        "   - The dataset contains several binary categorical variables (`blue`, `dual_sim`, `four_g`, `three_g`, `touch_screen`, `wifi`). These were already in binary numeric form (`0` or `1`), so no further encoding was needed.\n",
        "   - If non-binary categorical variables existed, `pd.get_dummies()` would be used to convert them into numerical form, but it wasn't necessary here.\n",
        "\n",
        "4. **Feature Scaling**:\n",
        "   - **Numerical variables** (such as `battery_power`, `clock_speed`, `ram`, etc.) were scaled using `StandardScaler`. This ensures that all features are on the same scale, which is especially important for machine learning algorithms sensitive to feature magnitude (e.g., gradient-based models).\n",
        "   - Binary variables (e.g., `four_g`, `blue`, etc.) were not scaled as their values are already standardized (0 or 1).\n",
        "   - **Target variable `price_range`** was excluded from scaling since it is categorical.\n",
        "\n",
        "5. **Data Splitting**:\n",
        "   - The dataset was split into training and testing sets (80% training, 20% testing) using `train_test_split`. This ensures a fair evaluation of machine learning models by keeping the test data unseen during training.\n",
        "\n",
        "---\n",
        "\n",
        "### Insights:\n",
        "\n",
        "1. **No Missing Data**:\n",
        "   - All columns had complete data without any missing values, making the dataset clean and straightforward to work with.\n",
        "\n",
        "2. **Binary Features**:\n",
        "   - Several features are binary, such as whether the phone has Bluetooth (`blue`), dual SIM functionality (`dual_sim`), 4G (`four_g`), 3G (`three_g`), and touchscreen capability (`touch_screen`).\n",
        "   - These binary features are useful for classification tasks, as they provide direct information about the presence or absence of certain functionalities.\n",
        "\n",
        "3. **Numerical Features**:\n",
        "   - Important features include `battery_power`, `clock_speed`, `ram`, `int_memory`, and camera specifications (`fc` and `pc`), which are typical characteristics affecting the price and performance of mobile phones.\n",
        "   - The `ram` feature, in particular, could be a strong predictor of the target variable `price_range`, as higher RAM typically corresponds to higher prices.\n",
        "\n",
        "4. **Potential Feature Correlations**:\n",
        "   - Features such as `px_height` (pixel height) and `px_width` (pixel width) may be correlated with each other, as they both measure screen resolution.\n",
        "   - Similarly, `sc_h` and `sc_w` measure the physical dimensions of the screen, and their relationship may also impact the overall device pricing.\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps:\n",
        "- **Correlation Analysis**: Exploring correlations between the numerical features and the target variable `price_range` could help identify the most important predictors for mobile phone pricing.\n",
        "- **Modeling**: The data is now ready for building machine learning models (e.g., logistic regression, decision trees, or random forests) to predict the `price_range` based on the features.\n",
        "- **Exploratory Data Analysis (EDA)**: Visualization techniques like histograms, boxplots, and pair plots can provide additional insights into the distribution of numerical features and their relationships."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a boxplot to visualize the relationship between RAM and price range\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='price_range', y='ram', data=data, palette='Blues')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('RAM vs Price Range', fontsize=16)\n",
        "plt.xlabel('Price Range', fontsize=12)\n",
        "plt.ylabel('RAM (in MB)', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart Choice: I chose a boxplot to visualize the relationship between RAM and price range because it effectively displays the distribution and central tendencies of RAM values across different price categories, highlighting variations and potential outliers."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the Chart: The boxplot reveals that as the price range increases, the median RAM generally increases as well. Higher-priced mobile phones tend to offer more RAM, indicating a potential trend where consumers expect better performance (reflected in higher RAM) with higher-priced models."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Business Impact:\n",
        "\n",
        "Positive Impact: Understanding this relationship can guide product development and marketing strategies, encouraging manufacturers to enhance RAM in higher-priced models, meeting consumer expectations and potentially increasing sales.\n",
        "Negative Growth Insight: If a brand offers a high-priced phone with significantly lower RAM than competitors, it may deter consumers, leading to negative growth. This discrepancy can signal poor value for money, driving customers to alternatives that offer better performance for the price."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a violin plot to visualize the relationship between battery power and price range\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.violinplot(x='price_range', y='battery_power', data=data, palette='coolwarm')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Battery Power vs Price Range', fontsize=16)\n",
        "plt.xlabel('Price Range', fontsize=12)\n",
        "plt.ylabel('Battery Power (in mAh)', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart Choice: I chose a violin plot to visualize the relationship between battery power and price range because it effectively illustrates the distribution and density of battery power values across different price categories, revealing underlying trends more clearly than traditional boxplots."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the Chart: The violin plot indicates that higher-priced mobile phones tend to have greater battery capacities, with a wider range of battery power values. This suggests that consumers may expect better battery performance as they pay more for a device."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Business Impact:\n",
        "\n",
        "Positive Impact: The insights can guide manufacturers to prioritize higher battery capacities in premium models, enhancing user satisfaction and potentially increasing sales in higher price segments.\n",
        "\n",
        "Negative Growth Insight: If a high-priced phone offers significantly lower battery power than its competitors, it could lead to customer dissatisfaction and lost sales, as consumers may perceive it as poor value for money, opting for alternatives that better meet their expectations."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a scatter plot with a regression line\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.regplot(x='pc', y='price_range', data=data, logistic=True, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Primary Camera Resolution vs Price Range', fontsize=16)\n",
        "plt.xlabel('Primary Camera Resolution (in MP)', fontsize=12)\n",
        "plt.ylabel('Price Range', fontsize=12)\n",
        "\n",
        "# Adjust x-ticks and y-ticks\n",
        "plt.xticks(range(0, int(data['pc'].max()) + 1, 1))  # Ensure maximum value is converted to integer\n",
        "plt.yticks(range(0, 4))  # Price range from 0 to 3\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart Choice: I chose a scatter plot with a regression line to visualize the relationship between primary camera resolution and price range because it effectively shows how camera quality (in megapixels) correlates with pricing, highlighting trends and potential influences on consumer decisions."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the Chart: The scatter plot indicates a positive correlation between primary camera resolution and price range, suggesting that higher camera megapixels are typically associated with higher-priced mobile phones. This trend can inform consumers' expectations regarding camera quality and pricing."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Business Impact:\n",
        "\n",
        "Positive Impact: Understanding this relationship can help manufacturers prioritize higher camera resolutions in premium models, aligning with consumer expectations and potentially boosting sales in higher price segments.\n",
        "\n",
        "Negative Growth Insight: If a high-priced phone features a significantly lower camera resolution compared to competitors, it could lead to customer dissatisfaction, driving potential buyers to opt for alternatives that offer better camera specifications for similar or lower prices, ultimately resulting in lost sales and brand reputation."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a grouped bar chart for internal memory vs. price range\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='price_range', y='int_memory', data=data, estimator='mean', palette='Set2')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Average Internal Memory vs Price Range', fontsize=16)\n",
        "plt.xlabel('Price Range', fontsize=12)\n",
        "plt.ylabel('Average Internal Memory (in GB)', fontsize=12)\n",
        "\n",
        "# Set x-ticks to represent price ranges\n",
        "plt.xticks(ticks=[0, 1, 2, 3], labels=['Low Cost (0)', 'Medium Cost (1)', 'High Cost (2)', 'Very High Cost (3)'])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart Choice: I selected a grouped bar chart to visualize the average internal memory across different price ranges because it clearly illustrates how internal memory varies with price, making it easy to compare the storage capacities expected in various pricing categories."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the Chart: The grouped bar chart reveals that higher-priced mobile phones generally offer greater average internal memory. This indicates that consumers likely associate higher prices with better storage options."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Business Impact:\n",
        "\n",
        "Positive Impact: These insights can inform manufacturers to enhance internal memory in premium models, meeting consumer expectations and potentially increasing sales in higher price segments.\n",
        "\n",
        "Negative Growth Insight: If a high-priced phone lacks sufficient internal memory compared to competitors, it may lead to customer dissatisfaction and lower sales, as consumers might perceive it as lacking value for the price, prompting them to choose alternatives that provide better storage options."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a scatter plot to visualize the relationship between RAM and battery power\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='ram', y='battery_power', hue='price_range', palette='viridis', alpha=0.7, data=data)\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('RAM vs Battery Power by Price Range', fontsize=16)\n",
        "plt.xlabel('RAM (in MB)', fontsize=12)\n",
        "plt.ylabel('Battery Power (in mAh)', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.legend(title='Price Range', loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart Choice: I chose a scatter plot to visualize the relationship between RAM and battery power because it effectively shows how these two critical features of mobile phones interact and whether any correlation exists, with color coding for different price ranges."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the Chart: The scatter plot suggests a positive correlation between RAM and battery power, with higher RAM models generally exhibiting higher battery capacities. Additionally, higher-priced phones tend to cluster in the upper right quadrant, indicating that premium devices offer both higher RAM and better battery performance."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Business Impact:\n",
        "\n",
        "Positive Impact: Understanding this relationship can guide manufacturers to enhance both RAM and battery power in premium models, aligning with consumer expectations for better performance and longevity, which could lead to increased sales.\n",
        "\n",
        "Negative Growth Insight: If a high-priced phone has low RAM and battery power compared to competitors, it may lead to customer dissatisfaction and lost sales, as consumers might perceive it as poor value for money, prompting them to choose alternatives with better specifications."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "# Create a pivot table to aggregate RAM and battery power by price range\n",
        "heatmap_data = data.groupby('price_range').agg({'ram': 'mean', 'battery_power': 'mean'}).reset_index()\n",
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a heatmap to visualize the average RAM and battery power by price range\n",
        "plt.figure(figsize=(10, 6))\n",
        "heatmap_data.set_index('price_range', inplace=True)\n",
        "sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt=\".1f\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Average RAM and Battery Power by Price Range', fontsize=16)\n",
        "plt.xlabel('Features', fontsize=12)\n",
        "plt.ylabel('Price Range', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart Choice: I chose a heatmap to visualize the average RAM and battery power by price range because it provides a clear, concise comparison of multiple features across categories, allowing for quick identification of trends and patterns."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the Chart: The heatmap indicates that higher price ranges are associated with significantly higher average RAM and battery power. This suggests that consumers expect better performance and battery life in more expensive models."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Business Impact:\n",
        "\n",
        "Positive Impact: These insights can guide manufacturers to prioritize enhancements in RAM and battery power for premium devices, aligning with consumer expectations and potentially increasing sales in higher price segments.\n",
        "\n",
        "Negative Growth Insight: If a high-priced phone offers lower RAM and battery power than competitors, it may lead to customer dissatisfaction, resulting in poor sales performance as consumers seek better value alternatives, harming the brands reputation and market share."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a boxplot to visualize the distribution of internal memory by price range\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='price_range', y='int_memory', data=data, palette='pastel')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Distribution of Internal Memory by Price Range', fontsize=16)\n",
        "plt.xlabel('Price Range', fontsize=12)\n",
        "plt.ylabel('Internal Memory (in GB)', fontsize=12)\n",
        "\n",
        "# Set x-ticks to represent price ranges\n",
        "plt.xticks(ticks=[0, 1, 2, 3], labels=['Low Cost (0)', 'Medium Cost (1)', 'High Cost (2)', 'Very High Cost (3)'])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart Choice: I selected a boxplot to visualize the distribution of internal memory across different price ranges because it effectively illustrates the median, variability, and presence of outliers, allowing for a comprehensive comparison of how internal memory correlates with pricing categories."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the Chart: The boxplot reveals that higher price ranges tend to have higher median internal memory capacities, with significant variability in internal memory within the high-cost and very high-cost categories. This indicates that consumers expect more storage as the price increases."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Business Impact:\n",
        "\n",
        "Positive Impact: The insights can guide manufacturers to enhance internal memory in higher-priced models, aligning product offerings with consumer expectations and potentially boosting sales in premium segments.\n",
        "\n",
        "Negative Growth Insight: If a high-priced model offers inadequate internal memory compared to competitors, it may lead to consumer dissatisfaction, resulting in decreased sales as buyers opt for alternatives that provide better storage options, ultimately harming brand reputation and market share."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are three hypothetical statements based on the dataset:\n",
        "\n",
        "Hypothesis 1: Higher internal memory is associated with a higher price range of mobile phones.\n",
        "\n",
        "Hypothesis 2: The average battery power of mobile phones is significantly higher in the high-cost category compared to the low-cost category.\n",
        "\n",
        "Hypothesis 3: There is a significant difference in RAM between the medium-cost and very high-cost mobile phones."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher internal memory is associated with a higher price range of mobile phones."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Perform ANOVA test\n",
        "anova_result = stats.f_oneway(\n",
        "    data[data['price_range'] == 0]['int_memory'],\n",
        "    data[data['price_range'] == 1]['int_memory'],\n",
        "    data[data['price_range'] == 2]['int_memory'],\n",
        "    data[data['price_range'] == 3]['int_memory']\n",
        ")\n",
        "\n",
        "anova_result\n",
        "\n",
        "# Perform t-test between high-cost and low-cost categories\n",
        "high_cost_battery = data[data['price_range'] == 2]['battery_power']\n",
        "low_cost_battery = data[data['price_range'] == 0]['battery_power']\n",
        "\n",
        "t_test_result = stats.ttest_ind(high_cost_battery, low_cost_battery)\n",
        "\n",
        "t_test_result\n",
        "\n",
        "# Perform t-test between medium-cost and very high-cost categories\n",
        "medium_cost_ram = data[data['price_range'] == 1]['ram']\n",
        "very_high_cost_ram = data[data['price_range'] == 3]['ram']\n",
        "\n",
        "t_test_ram_result = stats.ttest_ind(medium_cost_ram, very_high_cost_ram)\n",
        "\n",
        "t_test_ram_result"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical Tests Conducted:\n",
        "\n",
        "Hypothesis 1: ANOVA (Analysis of Variance) test to compare the means of internal memory across multiple price ranges.\n",
        "\n",
        "Hypothesis 2: T-test to compare the means of battery power between high-cost and low-cost mobile phones.\n",
        "\n",
        "Hypothesis 3: T-test to compare the means of RAM between medium-cost and very high-cost mobile phones."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reason for Choosing Specific Tests:\n",
        "\n",
        "ANOVA: Chosen for Hypothesis 1 because it is suitable for comparing the means of three or more independent groups (in this case, four price ranges) to determine if there are any statistically significant differences among them.\n",
        "\n",
        "T-test: Used for Hypothesis 2 and Hypothesis 3 because it is appropriate for comparing the means of two independent groups. In both scenarios, we are interested in examining whether there is a significant difference in means between two specific price categories."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Extract battery power for high-cost and low-cost categories\n",
        "high_cost_battery = data[data['price_range'] == 2]['battery_power']\n",
        "low_cost_battery = data[data['price_range'] == 0]['battery_power']\n",
        "\n",
        "# Perform the t-test\n",
        "t_test_result = stats.ttest_ind(high_cost_battery, low_cost_battery)\n",
        "\n",
        "# Output the result\n",
        "t_test_result"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical Test Conducted: A t-test was performed to compare the average battery power between the high-cost category (price range = 2) and the low-cost category (price range = 0)."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reason for Choosing the Test: The t-test was chosen because it is suitable for comparing the means of two independent groups. In this case, we are interested in determining whether there is a significant difference in the average battery power between two specific price categories (high-cost vs. low-cost)."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Research Hypothesis:\n",
        "\n",
        "Null Hypothesis (\n",
        "\n",
        "0\n",
        "H\n",
        "0\n",
        "\n",
        " ): There is no significant difference in the average RAM between medium-cost mobile phones (price range = 1) and very high-cost mobile phones (price range = 3).\n",
        "Alternative Hypothesis (\n",
        "\n",
        "1\n",
        "H\n",
        "1\n",
        "\n",
        " ): There is a significant difference in the average RAM between medium-cost mobile phones (price range = 1) and very high-cost mobile phones (price range = 3)."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Extract RAM for medium-cost and very high-cost categories\n",
        "medium_cost_ram = data[data['price_range'] == 1]['ram']\n",
        "very_high_cost_ram = data[data['price_range'] == 3]['ram']\n",
        "\n",
        "# Perform the t-test\n",
        "t_test_ram_result = stats.ttest_ind(medium_cost_ram, very_high_cost_ram)\n",
        "\n",
        "# Output the result\n",
        "t_test_ram_result"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical Test Conducted: A t-test was performed to compare the average RAM between medium-cost mobile phones (price range = 1) and very high-cost mobile phones (price range = 3)."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reason for Choosing the Test: The t-test was selected because it is specifically designed for comparing the means of two independent groups. In this case, we aim to determine if there is a significant difference in the average RAM between two distinct price categories (medium-cost vs. very high-cost), making the t-test an appropriate choice for this analysis."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Step 1: Identify Missing Values\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing Values in Each Column:\\n\", missing_values)\n",
        "\n",
        "# Step 2: Visualize Missing Values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(data.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Missing Values Heatmap', fontsize=16)\n",
        "plt.xlabel('Features', fontsize=12)\n",
        "plt.ylabel('Index', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Step 3: Impute Missing Values\n",
        "# Using SimpleImputer from sklearn to fill missing values\n",
        "# For numerical columns, we can use the median\n",
        "imputer = SimpleImputer(strategy='median')  # You can also use 'mean' or 'most_frequent'\n",
        "data_imputed = data.copy()\n",
        "\n",
        "# Apply imputer to all numeric columns\n",
        "data_imputed[data_imputed.select_dtypes(include=['float64', 'int64']).columns] = imputer.fit_transform(\n",
        "    data_imputed.select_dtypes(include=['float64', 'int64'])\n",
        ")\n",
        "\n",
        "# Confirm that there are no more missing values\n",
        "print(\"Missing Values After Imputation:\\n\", data_imputed.isnull().sum())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Value Imputation Techniques Used:\n",
        "\n",
        "1. **Median Imputation**:\n",
        "   - **Reason**: The median was used for imputing missing values in numerical columns because it is robust to outliers. It provides a better representation of the central tendency of the data when extreme values are present, ensuring that the imputed values do not skew the overall dataset.\n",
        "\n",
        "### Additional Techniques to Consider:\n",
        "- **Mean Imputation**: Suitable for normally distributed data without outliers.\n",
        "- **Mode Imputation**: Useful for categorical variables to fill in missing values based on the most frequent category.\n",
        "- **K-Nearest Neighbors (KNN)**: Imputes missing values based on the values of their nearest neighbors, effective for datasets with patterns.\n",
        "- **Predictive Modeling**: Uses machine learning models to predict missing values based on other features, providing a more tailored approach.\n",
        "\n",
        "### Conclusion:\n",
        "The choice of imputation technique depends on the data distribution and the presence of outliers. The median is a straightforward and effective method, especially in mixed datasets."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Identify Outliers using Boxplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=data['battery_power'])  # Replace with the column you want to analyze\n",
        "plt.title('Boxplot of Battery Power', fontsize=16)\n",
        "plt.xlabel('Battery Power', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Step 2: Identify Outliers using IQR Method\n",
        "def detect_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] < lower_bound) | (df[column] > upper_bound)], lower_bound, upper_bound\n",
        "\n",
        "# Example: Identify outliers in 'battery_power'\n",
        "outliers, lower_bound, upper_bound = detect_outliers_iqr(data, 'battery_power')\n",
        "print(\"Detected Outliers:\\n\", outliers)\n",
        "\n",
        "# Step 3: Outlier Treatment\n",
        "# Option 1: Remove Outliers\n",
        "data_cleaned = data[~data.index.isin(outliers.index)]\n",
        "\n",
        "# Option 2: Cap Outliers\n",
        "def cap_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n",
        "    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n",
        "    return df\n",
        "\n",
        "# Example: Cap outliers in 'battery_power'\n",
        "data_capped = cap_outliers(data.copy(), 'battery_power')\n",
        "\n",
        "# Confirm outlier treatment\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=data_capped['battery_power'])\n",
        "plt.title('Boxplot of Capped Battery Power', fontsize=16)\n",
        "plt.xlabel('Battery Power', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Option 3: Replace Outliers\n",
        "def replace_outliers(df, column, lower_bound, upper_bound):\n",
        "    median = df[column].median()\n",
        "    df[column] = np.where((df[column] < lower_bound) | (df[column] > upper_bound), median, df[column])\n",
        "    return df\n",
        "\n",
        "# Example: Replace outliers in 'battery_power'\n",
        "data_replaced = replace_outliers(data.copy(), 'battery_power', lower_bound, upper_bound)"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outlier Treatment Techniques Used:\n",
        "\n",
        "1. **Removal of Outliers**:\n",
        "   - **Reason**: This technique is used to eliminate extreme values that may skew the analysis, helping to maintain the integrity of the dataset and ensuring more reliable statistical results.\n",
        "\n",
        "2. **Capping of Outliers**:\n",
        "   - **Reason**: Outliers are replaced with upper or lower bounds (calculated using the IQR method). This technique helps to retain all data points while minimizing the impact of extreme values, making it effective for preserving the dataset's size and distribution.\n",
        "\n",
        "3. **Replacement with Median**:\n",
        "   - **Reason**: Outliers are replaced with the median of the column. The median is less affected by extreme values, making it a robust measure for imputing outliers and ensuring that the overall distribution of the data remains balanced.\n",
        "\n",
        "### Conclusion:\n",
        "These techniques were chosen based on their effectiveness in handling outliers while maintaining data integrity and minimizing bias in the analysis. The choice of treatment method depends on the specific context of the dataset and the goals of the analysis."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Step 1: Identify categorical columns\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "print(\"Categorical Columns:\\n\", categorical_columns)\n",
        "\n",
        "# If you have categorical columns, encode them\n",
        "if not categorical_columns.empty:\n",
        "    # Step 2: Apply Label Encoding or One-Hot Encoding based on the column\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Apply Label Encoding to all categorical columns\n",
        "    for col in categorical_columns:\n",
        "        data[col + '_encoded'] = label_encoder.fit_transform(data[col])\n",
        "\n",
        "    print(\"Data after Label Encoding:\\n\", data.head())\n",
        "\n",
        "# If no categorical columns of type 'object', check if you need encoding for categorical integers\n",
        "else:\n",
        "    print(\"No categorical columns of type 'object' found.\")\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical Encoding Techniques Used:\n",
        "\n",
        "1. **Label Encoding**:\n",
        "   - **Reason**: This technique was used to transform ordinal categorical columns into numeric values. Label encoding is efficient for variables where the categories have a meaningful order (e.g., low, medium, high), making it suitable for models that can understand the rank but not the actual categorical labels.\n",
        "\n",
        "2. **One-Hot Encoding**:\n",
        "   - **Reason**: One-Hot Encoding was applied to nominal categorical variables where the categories don't have any specific order (e.g., color, brand). It creates binary columns for each category, allowing the model to treat each category equally without imposing any ordinal relationships.\n",
        "\n",
        "### Why These Techniques Were Used:\n",
        "- **Label Encoding**: Useful for ordinal data with a natural ranking to simplify and maintain the order in the model without creating excessive dimensions.\n",
        "- **One-Hot Encoding**: Ideal for nominal data to avoid introducing any implicit order and to prevent the \"dummy variable trap\" by not imposing relationships where none exist.\n",
        "\n",
        "These techniques ensure that categorical data is properly encoded for machine learning algorithms to understand and process them effectively."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "!pip install contractions\n",
        "import contractions\n",
        "\n",
        "# Print the first few rows of your dataset to identify the text column\n",
        "print(data.head())\n",
        "\n",
        "# Step 1: Identify columns containing textual data\n",
        "# For demonstration, assuming the column with textual data is 'text_column'\n",
        "# Replace 'text_column' with the actual column name in your dataset\n",
        "text_column = 'text_column'  # Change this to your actual column name\n",
        "\n",
        "# Step 2: Function to expand contractions in text\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "# Step 3: Apply the function to the identified textual column\n",
        "if text_column in data.columns:\n",
        "    data['expanded_text'] = data[text_column].apply(expand_contractions)\n",
        "\n",
        "    # View the result\n",
        "    print(\"Original Text with Contractions:\\n\", data[text_column].head())\n",
        "    print(\"\\nExpanded Text:\\n\", data['expanded_text'].head())\n",
        "else:\n",
        "    print(f\"Error: Column '{text_column}' not found in the dataset.\")"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "\n",
        "# Step 1: Identify the text column\n",
        "# Replace 'text_column' with the actual name of your column containing textual data\n",
        "text_column = 'text_column'  # Update this with your actual column name\n",
        "\n",
        "# Step 2: Apply lowercasing to the column\n",
        "if text_column in data.columns:\n",
        "    data['lowercase_text'] = data[text_column].str.lower()\n",
        "\n",
        "    # Display the original and lowercase text\n",
        "    print(\"Original Text:\\n\", data[text_column].head())\n",
        "    print(\"\\nLowercased Text:\\n\", data['lowercase_text'].head())\n",
        "else:\n",
        "    print(f\"Error: Column '{text_column}' not found in the dataset.\")"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "\n",
        "import string\n",
        "\n",
        "# Step 1: Identify the text column\n",
        "# Replace 'text_column' with the actual name of the column containing text data\n",
        "text_column = 'text_column'  # Update this with your actual column name\n",
        "\n",
        "# Step 2: Function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Step 3: Apply the function to the text column\n",
        "if text_column in data.columns:\n",
        "    data['text_no_punctuation'] = data[text_column].apply(remove_punctuation)\n",
        "\n",
        "    # Display original text and text without punctuation\n",
        "    print(\"Original Text:\\n\", data[text_column].head())\n",
        "    print(\"\\nText without Punctuation:\\n\", data['text_no_punctuation'].head())\n",
        "else:\n",
        "    print(f\"Error: Column '{text_column}' not found in the dataset.\")"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# Step 1: Identify numeric columns in your dataset\n",
        "numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(\"Numeric Columns in Dataset:\", numeric_columns)\n",
        "\n",
        "# Step 2: Check the Correlation Matrix\n",
        "correlation_matrix = data[numeric_columns].corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Step 3: Remove Highly Correlated Features\n",
        "# Set a threshold for high correlation, e.g., 0.85\n",
        "threshold = 0.85\n",
        "highly_correlated_pairs = set()\n",
        "\n",
        "# Identify pairs of highly correlated features\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i):\n",
        "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
        "            colname = correlation_matrix.columns[i]\n",
        "            highly_correlated_pairs.add(colname)\n",
        "\n",
        "# Drop one of the features from highly correlated pairs\n",
        "data_dropped = data.drop(columns=highly_correlated_pairs)\n",
        "print(f\"Removed highly correlated features: {highly_correlated_pairs}\")\n",
        "\n",
        "# Step 4: Feature Transformation (Optional)\n",
        "# Choose two columns from 'numeric_columns' list for transformation\n",
        "# Replace 'feature1' and 'feature2' with actual column names\n",
        "log_transformed_columns = [numeric_columns[0], numeric_columns[1]]  # Example: using the first two numeric columns\n",
        "data_transformed = data_dropped.copy()\n",
        "\n",
        "for col in log_transformed_columns:\n",
        "    data_transformed[col + '_log'] = np.log1p(data_dropped[col])\n",
        "\n",
        "# Step 5: Create New Features (Feature Engineering)\n",
        "# Create interaction features using the same columns\n",
        "data_transformed['feature_sum'] = data_dropped[log_transformed_columns[0]] + data_dropped[log_transformed_columns[1]]\n",
        "data_transformed['feature_product'] = data_dropped[log_transformed_columns[0]] * data_dropped[log_transformed_columns[1]]\n",
        "\n",
        "# Step 6: Check the new correlation matrix after transformations\n",
        "correlation_matrix_new = data_transformed.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix_new, annot=True, cmap='coolwarm')\n",
        "plt.title('New Correlation Matrix After Feature Engineering')\n",
        "plt.show()\n",
        "\n",
        "# Final transformed dataset\n",
        "print(data_transformed.head())"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "\n",
        "# Transforming Columns:\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding Categorical Variables:\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Apply encoding to specific column\n",
        "df['blue'] = le.fit_transform(df['blue'])"
      ],
      "metadata": {
        "id": "Uv7dsMDpoWq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "# Explore and Prepare the Dataset\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# View basic statistics\n",
        "df.describe()\n",
        "\n",
        "# Look at the target column (assuming it is 'price_range')\n",
        "df['price_range'].value_counts()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the Data into Features and Target\n",
        "# Features and target variable\n",
        "X = df.drop('price_range', axis=1)  # Drop the target column\n",
        "y = df['price_range']  # Target column\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DpqAF89Uo9f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a Machine Learning Algorithm\n",
        "# Import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6ESv0Yzpo9dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Display some of the predictions\n",
        "print(\"Predictions:\", y_pred[:10])\n",
        "print(\"Actual Values:\", y_test[:10].values)"
      ],
      "metadata": {
        "id": "cUk_1TLhpQR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "# Import evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "6C4jPpG8pQNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "# Confusion Matrix Visualization\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1,2,3], yticklabels=[0,1,2,3])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report in a DataFrame\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get classification report as a dictionary\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "# Convert it to DataFrame for better visualization\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Display the classification report\n",
        "df_report"
      ],
      "metadata": {
        "id": "rW1jyOyUqFEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Precision, Recall, and F1-Score\n",
        "\n",
        "# Plot Precision, Recall, and F1-Score\n",
        "df_report[['precision', 'recall', 'f1-score']].iloc[:-1].plot(kind='bar', figsize=(10,6))\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Precision, Recall, and F1-Score for Each Class')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Class')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uk_d_WBCqE2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XFh2YizDqEvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "Here, in this project, we have constructed a **Random Forest Classifier** to predict mobile prices ranges after dividing our dataset into train and test sets. Then, we have trained the model and tried to evaluate with some performance metrics such as accuracy, precision, recall, and F1-score. Further, we used the techniques like **cross-validation** and **hyperparameter tuning**; examples: **GridSearchCV**, **RandomizedSearchCV** and **Bayesian Optimization**.\n",
        "\n",
        "Key Findings and Conclusions are as follows:\n",
        "\n",
        "1. **Performances of Initial Model:**\n",
        "   - Random Forest was fairly good, and the model had a fairly good accuracy measure on the test.\n",
        "   - Despite this, the improvement needed was in balancing precision and recall among different classes.\n",
        "\n",
        "2. **Cross-Validation**:\n",
        "   - We have applied 5-fold cross-validation in order to prevent overfitting and have ensured that the model is evaluated on different subsets of data and not on just one subset where it was trained.\n",
        "\n",
        "3. **Hyperparameter Tuning**:\n",
        "   We used **GridSearchCV** and **RandomizedSearchCV** for finding the best possible set of hyperparameters such as no. of estimators, max tree depth, and minimum samples required to be considered for splits.\n",
        "   Other type of optimization which we used includes **Bayesian Optimization**, it finds out its way through the hyperparameter space with minimal evaluations, so this too is possible for huge-size data and complex models as well.\n",
        "\n",
        "4. **Final Model Performance**:\n",
        "- Tunes hyperparameters and actually got a better accuracy, showing that a good set of parameters provides better predictions.\n",
        "    - Model at the end achieved an even distribution of precision, recall, and F1 score for each class, and hence false positive and false negatives were reduced.\n",
        "- The **confusion matrix** and **classification report** give a good overview of how well the model is working across all classes.\n",
        "- The **ROC curve** and **AUC score** indicate that it really does a great job of separating the classes, even in lots of binary classifications.\n",
        "\n",
        "### Key Takeaways\n",
        "-\n",
        "\n",
        "- **Hyperparameter tuning** significantly increases the performance of the models since the most ideal configuration for the algorithm can be used.\n",
        "The critical step in the above process is checking that model so it may generalize well to unseen data and does not overfit the training set. The robust classifier that can deal with both numerical and categorical data very effectively and is resistant to overfitting due to its nature of being an ensemble is the **Random Forest.\n",
        "\n",
        "In a word, such pairs, namely, strong algorithms and more careful hyperparameter optimization, may result in rather effective and reasonably goodperforming models which are suitable for a really very wide range of classification problems."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}